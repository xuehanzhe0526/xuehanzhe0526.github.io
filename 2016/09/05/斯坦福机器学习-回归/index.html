<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="What hurts more,the pain of hard work or the pain of regret.">
    <meta name="keyword" content="null">
    <meta name="theme-color" content="#600090">
    <meta name="msapplication-navbutton-color" content="#600090">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="#600090">
    <link rel="shortcut icon" href="https://cdn4.iconfinder.com/data/icons/ionicons/512/icon-person-128.png">
    <link rel="alternate" type="application/atom+xml" title="Haozhe" href="/atom.xml">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/animate.css/3.5.2/animate.min.css">
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.css">
    <title>
        
        斯坦福机器学习-线性回归｜Haozhe&#39;s blog
        
    </title>

    <link rel="canonical" href="http://yoursite.com/2016/09/05/斯坦福机器学习-回归/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/blog-style.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">
</head>

<style>

    header.intro-header {
        background-image: url('http://7xrw7v.com1.z0.glb.clouddn.com/1485527729222.jpg')
    }
</style>
<!-- hack iOS CSS :active style -->
<body ontouchstart="" class="animated fadeIn">
<!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top " id="nav-top" data-ispost = "true" data-istags="false
" data-ishome = "false" >
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand animated pulse" href="/">
                <span class="brand-logo">
                    Haozhe
                </span>
                's Blog
            </a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <!-- /.navbar-collapse -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
					
                    
                        
							
                        <li>
                            <a href="/tags/">tags</a>
                        </li>
							
						
                    
					
					
                </ul>
            </div>
        </div>
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
//    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>

<!-- Main Content -->

<!--only post-->


<img class="wechat-title-img"
     src="http://7xrw7v.com1.z0.glb.clouddn.com/148552521631.jpg#博文默认的图片">


<style>
    
    header.intro-header {
        background-image: url('http://7xrw7v.com1.z0.glb.clouddn.com/148552521631.jpg#博文默认的图片')
    }

    
</style>

<header class="intro-header">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 text-center">
                <div class="post-heading">
                    <h1>斯坦福机器学习-线性回归</h1>
                    
                    <span class="meta">
                         作者 Haozhe Xue
                        <span>
                          日期 2016-09-05
                         </span>
                    </span>
                    <div class="tags text-center">
                        
                        <a class="tag" href="/tags/#斯坦福机器学习"
                           title="斯坦福机器学习">斯坦福机器学习</a>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="post-title-haojen">
        <span>
            斯坦福机器学习-线性回归
        </span>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <!-- Post Container -->
            <div class="col-lg-8 col-lg-offset-1 col-sm-9 post-container">
                <p>摘要：</p>
<ul>
<li>单变量线性回归</li>
<li>代价函数</li>
<li>梯 度 下 降</li>
<li>学习率</li>
<li>多 变 量 线 性 回 归</li>
<li>特 征 缩 放</li>
<li>多 项 式 回 归</li>
<li>正 规 方 程</li>
</ul>
<a id="more"></a>
<p>不积跬步，无以至千里；不积小流，无以成江海。”<br>——荀子《劝学篇》</p>
<p>这句话写在开头，以作警示。</p>
<p>未来几天，将男神：Andrew Ng 的机器学习视频过一遍，该系列博客主要来自视频及网上Ryan Cheung的笔记。</p>
<h3 id="单变量线性回归-LINEAR-REGRESSION-WITH-ONE-VARIABLE"><a href="#单变量线性回归-LINEAR-REGRESSION-WITH-ONE-VARIABLE" class="headerlink" title="单变量线性回归 LINEAR REGRESSION WITH ONE VARIABLE"></a>单变量线性回归 LINEAR REGRESSION WITH ONE VARIABLE</h3><h4 id="模-型-表-达-MODEL-REPRESENTATION"><a href="#模-型-表-达-MODEL-REPRESENTATION" class="headerlink" title="模 型 表 达 MODEL REPRESENTATION"></a>模 型 表 达 MODEL REPRESENTATION</h4><p>假使我们回归问题的训练集(Training Set)如下表所示:</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/73c6b4e5a7705360cda20eff49dead22.png" alt=""></p>
<p>我们将要用来描述这个回归问题的标记如下:<br><img src="http://7xrw7v.com1.z0.glb.clouddn.com/be3df77f13e39781bbfc35c14d344ff1.png" alt=""></p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/8dca07a0928836e4c08a3ac70d6c47b9.png" alt=""></p>
<p>因而,要解决房价预测问题,我们实际上是<code>要将训练集“喂”给我们的学习算法,</code>进而学习得<br>一个假设 h,然后将我们要预测的房屋的尺寸作为输入变量输入给 h,预测出该房屋的交易价<br>格作为输出变量输出为结果。</p>
<p>对于我们的房价预测问题,我们该如何表达 h?</p>
<p>一种可能的表达方式为:<img src="http://7xrw7v.com1.z0.glb.clouddn.com/cb9cbe7a8bbf807e946625171e960672.png" alt=""></p>
<p><code>因为只含有一个特征/输入变量,因此这样的问题叫作单变量线性回归问题。</code></p>
<h4 id="代-价-函-数-COST-FUNCTION"><a href="#代-价-函-数-COST-FUNCTION" class="headerlink" title="代 价 函 数 ( COST FUNCTION)"></a>代 价 函 数 ( COST FUNCTION)</h4><p>现在要做的便是为我们的模型选择<br>合适的参数(parameters)$θ_0$ 和$θ_1$ 。<br>在房价问题这个<br>例子中便是在 y 轴上的截距和直线的斜率。</p>
<p>我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度,模型所预测的值与训<br>练集中实际值之间的差距(下图中蓝线所指)就是<code>建模误差(modeling error)。</code><br><img src="http://7xrw7v.com1.z0.glb.clouddn.com/4bf409d21695a63dec094e9e7ba487e4.png" alt=""></p>
<p><code>我们的目标：</code><br>选择出可以使得建模误差的平方和能够最小的模型参数。<br>即：使得<code>代价函数</code><img src="http://7xrw7v.com1.z0.glb.clouddn.com/237776bde0b15795cc0954d0edfaa23f.png" alt="">最小。</p>
<p>我们绘制一个等高线图,三个坐标分别为$θ_0$ 和$θ_1$ 和 $J(θ_0, θ_1 )$:<br><img src="http://7xrw7v.com1.z0.glb.clouddn.com/dedd34eaf4ffb44031cecc5c485cd9dd.png" alt=""><br>可以看出在三维空间中存在一个使得 $J(θ_0, θ_1 )$最小的点。</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/c87a08e34628b75b929e4c42bada5fe5.png" alt=""></p>
<h4 id="梯-度-下-降-GRADIENT-DESCENT"><a href="#梯-度-下-降-GRADIENT-DESCENT" class="headerlink" title="梯 度 下 降 ( GRADIENT DESCENT)"></a>梯 度 下 降 ( GRADIENT DESCENT)</h4><p>为了求代价函数$J(θ_0, θ_1 )$的最小值，我们将使用梯度下降算法。<br>梯度下降是一个用来求函数最小值的算法。</p>
<p>梯度下降算法的思想：<br><img src="http://7xrw7v.com1.z0.glb.clouddn.com/5b50132c0be823bd52f939050ee25734.png" alt=""><br><img src="http://7xrw7v.com1.z0.glb.clouddn.com/9877c74194eff74b247555aa7376fa2a.png" alt=""></p>
<h5 id="批量梯度下降-batch-gradient-descent-算法"><a href="#批量梯度下降-batch-gradient-descent-算法" class="headerlink" title="批量梯度下降(batch gradient descent)算法"></a>批量梯度下降(batch gradient descent)算法</h5><p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/dfe92fc85f0cd7d85ed771235e5a10d6.png" alt=""></p>
<p>其中<code>α是学习率(learning rate)</code>,它决定了我们沿着能让代价函数下降程度最大的方向向下迈<br>出的步子有多大,在批量梯度下降中,我们每一次都同时让所有的参数减去学习速率乘以代价<br>函数的导数。</p>
<h4 id="对-线-性-回-归-运-用-梯-度-下-降-法"><a href="#对-线-性-回-归-运-用-梯-度-下-降-法" class="headerlink" title="对 线 性 回 归 运 用 梯 度 下 降 法"></a>对 线 性 回 归 运 用 梯 度 下 降 法</h4><p>对我们之前的线性回归问题运用梯度下降法,<code>关键在于求出代价函数的导数,</code>即:<br><img src="http://7xrw7v.com1.z0.glb.clouddn.com/1957e346e9c2205084bfa13262ffaec2.png" alt=""></p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/cc634ab0911b9e5fdf90a3a9f539c492.png" alt=""></p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/929a7dab00fc05cbdc9b939ec07a2ec0.png" alt=""></p>
<p>注意：对于凸函数（convex function）只有一个全局最优解。</p>
<h3 id="多-变-量-线-性-回-归"><a href="#多-变-量-线-性-回-归" class="headerlink" title="多 变 量 线 性 回 归"></a>多 变 量 线 性 回 归</h3><h4 id="多-维-特-征-MULTIPLE-FEATURES"><a href="#多-维-特-征-MULTIPLE-FEATURES" class="headerlink" title="多 维 特 征 ( MULTIPLE FEATURES)"></a>多 维 特 征 ( MULTIPLE FEATURES)</h4><p>现在我们对房价模型增加更多的特征,例如<br>房间数楼层等,构成一个含有多个变量的模型,模型中的特征为(x 1 ,x 2 ,…,x n )。</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/e6888adc50af3e60378e7bf94ac5d51a.png" alt=""></p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/d936b216cc8e8af416254da51b1fe7f0.png" alt=""></p>
<p>支持多变量的假设 h 表示为:<br><img src="http://7xrw7v.com1.z0.glb.clouddn.com/bb07e6c00c62a26fff4bf38f713bcb8b.png" alt=""></p>
<p>引入$X_0$=1</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/6615106f1da64c63368bb7406a8c9155.png" alt=""><br>此时模型中的参数是一个 n+1 纬的向量,任何一个训练实例也都是 n+1 纬的向量,特征矩阵<br>X 的纬度是 m*(n+1)。</p>
<p>因此公式简化为：<br><img src="http://7xrw7v.com1.z0.glb.clouddn.com/b03b7668b63a8aa1fa853f7a2d7e085f.png" alt="">其中上标 T 代表矩阵转置。</p>
<h4 id="多-变-量-梯-度-下-降-GRADIENT-DESCENT-FOR-MULTIPLE-VARIABLES"><a href="#多-变-量-梯-度-下-降-GRADIENT-DESCENT-FOR-MULTIPLE-VARIABLES" class="headerlink" title="多 变 量 梯 度 下 降 ( GRADIENT DESCENT FOR MULTIPLE VARIABLES)"></a>多 变 量 梯 度 下 降 ( GRADIENT DESCENT FOR MULTIPLE VARIABLES)</h4><p>在多变量线性回归中,我们也构建一个代价函数,则这个代价函数<br>是所有建模误差的平方和,即:<br><img src="http://7xrw7v.com1.z0.glb.clouddn.com/49c0c24e67b30da7ebe919d9351d4af2.png" alt=""></p>
<p><code>我们的目标：</code>找出使得代价函数最小的一系列参数。</p>
<p><code>多变量线性回归的批量梯度下降算法为:</code><br><img src="http://7xrw7v.com1.z0.glb.clouddn.com/0eb341cbbd759c101dc654c414876369.png" alt=""></p>
<p>即：</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/d9008bae69016724fcf434e0e1ed127f.png" alt=""></p>
<p>求导数后得到:</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/4265396384c7510aa89a3e82cffc51a3.png" alt=""></p>
<p>我们 开始随机选择一系列的参数直,计算所有的预测结果后,再给所有的参数一个新的值,如此循环直到收敛。</p>
<h4 id="特-征-缩-放-FEATURE-SCALING"><a href="#特-征-缩-放-FEATURE-SCALING" class="headerlink" title="特 征 缩 放 ( FEATURE SCALING)"></a>特 征 缩 放 ( FEATURE SCALING)</h4><p><code>面对多维特征问题的时候,我们要保证这些特征都具有相近的尺度,这将帮助梯度下降算法更快地收敛。</code></p>
<p>例子：</p>
<p>房价问题为例,假设我们使用两个特征,房屋的尺寸和房间的数量,尺寸的直为 0-2000 平方英尺,而房间数量的直则是 0-5,以两个参数分别为横纵坐标,绘制代价函数的等高线图能看出图像会显得很扁,梯度下降算法需要非常多次的迭代才能收敛。</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/66c0544a8ad1140f07f09c565bd333b8.png" alt=""></p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/14a49ba53cc09749621f6c837716f972.png" alt=""></p>
<h4 id="学-习-率-LEARNING-RATE"><a href="#学-习-率-LEARNING-RATE" class="headerlink" title="学 习 率 (LEARNING RATE)"></a>学 习 率 (LEARNING RATE)</h4><p>我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/c28d8c9c51c4b7138aab24e3f8ee2ad4.png" alt=""></p>
<p><code>其他方法：</code><br>也有一些自动测试是否收敛的方法,例如将代价函数的变化直与某个阀直(例如 0.001)进行比较,<br>但通常看上面这样的图表更好。</p>
<ul>
<li>如果学习率α过小,则达到收敛所需的迭代次数<br>会非常高</li>
<li>如果学习率α过大,每次迭代可能不会减小代价函数,可能会越过局部最小值导致<br>无法收敛。</li>
</ul>
<p>通常可以考虑尝试这些学习率:</p>
<p>$\alpha$ = 0.001,  0.003,  0.01,  0.03,  0.1,  0.3,  1, 3, 10</p>
<h3 id="多-项-式-回-归-POLYNOMIAL-REGRESSION"><a href="#多-项-式-回-归-POLYNOMIAL-REGRESSION" class="headerlink" title="多 项 式 回 归 ( POLYNOMIAL REGRESSION)"></a>多 项 式 回 归 ( POLYNOMIAL REGRESSION)</h3><p>线性回归并不适用于所有数据,有时我们需要曲线来适应我们的数据,比如一个二次方模型:</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/24f0d9e6c6e035b668030e76167e9776.png" alt=""></p>
<p>或者三次方模型:</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/8ed43e9ff8d9b2746ab9bd702a184eec.png" alt=""></p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/ca01b038d3afca5f275e823f4471f8f6.png" alt=""></p>
<p>通常我们需要先观察数据然后再决定准备尝试怎样的模型。</p>
<p>方法：我们可以令</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/c9c07272348a20e2f5f0d86d38f4f97e.png" alt=""><br>从而将模型转化为线性回归模型。</p>
<p><code>注:如果我们采用多项式回归模型,在运行梯度下降算法前,
特征缩放非常有必要。</code></p>
<h3 id="正-规-方-程-NORMAL-EQUATION"><a href="#正-规-方-程-NORMAL-EQUATION" class="headerlink" title="正 规 方 程 ( NORMAL EQUATION)"></a>正 规 方 程 ( NORMAL EQUATION)</h3><p>到目前为止,我们都在使用梯度下降算法,但是对于某些线性回归问题,正规方程方法是更好的解决方案。</p>
<p><code>正规方程是通过求解下面的方程来找出使得代价函数最小的参数的:</code><br><img src="http://7xrw7v.com1.z0.glb.clouddn.com/f4963307a27d5554ae0113c924c8e110.png" alt=""></p>
<p>假设我们的训练集特征矩阵为 X(包含了 x 0 =1)并且我们的训练集结果为向量 y,则利用正规<br>方程解出向量</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/74c6fdd54aa8aaeb56fe72b3fba78046.png" alt=""></p>
<p>上标 T 代表矩阵转置,上标-1 代表矩阵的逆。</p>
<h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><p>以下表所示数据为例:</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/ddd9a6382bbab5ebf4ae656b0a6daad7.png" alt=""></p>
<p>运用正规方程方法求解参数:</p>
<p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/e4ad4eaab52da9c8e421ff1a33fa1b14.png" alt=""></p>
<p>在 Octave 中,正规方程写作:pinv(X’<em>X)</em>X’*y</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">注:对于那些不可逆的矩阵(通常是因为特征之间不独立,如同时包含英尺</div><div class="line">  为单位的尺寸和米为单位的尺寸两个特征,也有可能是特征数量大于训</div><div class="line">  练集的数量),正规方程方法是不能用的。</div></pre></td></tr></table></figure>
<h4 id="梯度下降与正规方程的比较"><a href="#梯度下降与正规方程的比较" class="headerlink" title="梯度下降与正规方程的比较"></a>梯度下降与正规方程的比较</h4><p><img src="http://7xrw7v.com1.z0.glb.clouddn.com/19893cefee6385ccd1c1228d9b4b7e9a.png" alt=""></p>

                <hr>
                
                <!-- 多说 Share start -->
                <div class="ds-share"
                     style="text-align: right"
                     data-thread-key="2016/09/05/斯坦福机器学习-回归/"
                     data-title="斯坦福机器学习-线性回归"
                     data-url="http://yoursite.com/2016/09/05/斯坦福机器学习-回归/"
                     data-images=""
                     data-content="摘要：

单变量线性回归
代价函数
梯 度 下 降
学习率
多 变 量 线 性 回 归
特 征... | Haozhe&#39;s blog ">
                    <div class="ds-share-inline">
                        <ul class="ds-share-icons-16">
                            <li data-toggle="ds-share-icons-more"><a class="ds-more" href="#">分享到：</a></li>
                            <li><a class="ds-wechat flat" href="javascript:void(0);" data-service="wechat">微信</a></li>
                            <li><a class="ds-weibo flat" href="javascript:void(0);" data-service="weibo">微博</a></li>
                            <li><a class="ds-douban flat" href="javascript:void(0);" data-service="douban">豆瓣</a></li>
                        </ul>
                        <div class="ds-share-icons-more">
                        </div>
                    </div>
                    <hr>
                </div>
                <!-- 多说 Share end-->
                

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2016/09/07/斯坦福：逻辑回归/" data-toggle="tooltip" data-placement="top"
                           title="斯坦福机器学习：逻辑回归">&larr; Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2016/09/04/Pycharm无法切换搜狗输入法/" data-toggle="tooltip" data-placement="top"
                           title="Pycharm无法切换搜狗输入法">Next Post &rarr;</a>
                    </li>
                    
                </ul>

                
                <!-- 多说评论框 start -->
                <div class="comment">
                    <div class="ds-thread"
                         data-thread-key="2016/09/05/斯坦福机器学习-回归/"
                         data-title="斯坦福机器学习-线性回归"
                         data-url="http://yoursite.com/2016/09/05/斯坦福机器学习-回归/">
                    </div>
                </div>
                <!-- 多说评论框 end -->
                

                

            </div>

            <div class="hidden-xs col-sm-3 toc-col">
                <div class="toc-wrap">
                    <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#单变量线性回归-LINEAR-REGRESSION-WITH-ONE-VARIABLE"><span class="toc-text">单变量线性回归 LINEAR REGRESSION WITH ONE VARIABLE</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#模-型-表-达-MODEL-REPRESENTATION"><span class="toc-text">模 型 表 达 MODEL REPRESENTATION</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#代-价-函-数-COST-FUNCTION"><span class="toc-text">代 价 函 数 ( COST FUNCTION)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#梯-度-下-降-GRADIENT-DESCENT"><span class="toc-text">梯 度 下 降 ( GRADIENT DESCENT)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#批量梯度下降-batch-gradient-descent-算法"><span class="toc-text">批量梯度下降(batch gradient descent)算法</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#对-线-性-回-归-运-用-梯-度-下-降-法"><span class="toc-text">对 线 性 回 归 运 用 梯 度 下 降 法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多-变-量-线-性-回-归"><span class="toc-text">多 变 量 线 性 回 归</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#多-维-特-征-MULTIPLE-FEATURES"><span class="toc-text">多 维 特 征 ( MULTIPLE FEATURES)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#多-变-量-梯-度-下-降-GRADIENT-DESCENT-FOR-MULTIPLE-VARIABLES"><span class="toc-text">多 变 量 梯 度 下 降 ( GRADIENT DESCENT FOR MULTIPLE VARIABLES)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#特-征-缩-放-FEATURE-SCALING"><span class="toc-text">特 征 缩 放 ( FEATURE SCALING)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#学-习-率-LEARNING-RATE"><span class="toc-text">学 习 率 (LEARNING RATE)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多-项-式-回-归-POLYNOMIAL-REGRESSION"><span class="toc-text">多 项 式 回 归 ( POLYNOMIAL REGRESSION)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#正-规-方-程-NORMAL-EQUATION"><span class="toc-text">正 规 方 程 ( NORMAL EQUATION)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#例子"><span class="toc-text">例子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#梯度下降与正规方程的比较"><span class="toc-text">梯度下降与正规方程的比较</span></a></li></ol></li></ol>
                </div>
            </div>
        </div>

        <div class="row">
            <!-- Sidebar Container -->

            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5 class="text-center">
                        <a href="/tags/">FEATURED TAGS</a>
                    </h5>
                    <div class="tags">
                        
                        <a class="tag" href="/tags/#斯坦福机器学习"
                           title="斯坦福机器学习">斯坦福机器学习</a>
                        
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
                <div style="margin-top: 20px;">
                    <h5 class="text-center">FRIENDS</h5>
                    <ul class="list-inline text-center">
                        
                        <li><a href="http://www.hankcs.com/">hankcs</a></li>
                        
                        <li><a href="http://www.lintcode.com/zh-cn/ladder/2/">lintcode</a></li>
                        
                        <li><a href="http://www.jiuzhang.com/solutions/">jiuzhang</a></li>
                        
                    </ul>
                </div>
                
            </div>
        </div>

    </div>
</article>


<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
    // dynamic User by Hux
    var _user = 'xuehaozhe';

    // duoshuo comment query.
    var duoshuoQuery = {short_name: _user};
    (function () {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';
        ds.async = true;
        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
</script>
<!-- 多说公共JS代码 end -->





<!-- Footer -->
<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 text-center">
                <br>
                <ul class="list-inline text-center">
                
                
                    <li>
                        <a target="_blank" href="https://twitter.com/xuehaozhe">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                
                
                    <li>
                        <a target="_blank" href="https://www.zhihu.com/people/xuehaozhe0526">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa  fa-stack-1x fa-inverse">知</i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="http://weibo.com/fendoujianchi">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-weibo fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                
                    <li>
                        <a target="_blank"  href="https://github.com/xuehanzhe0526">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Haozhe 2017
                    <br>
                    <span id="busuanzi_container_site_pv" style="font-size: 12px;">PV: <span id="busuanzi_value_site_pv"></span> Times</span>
                    <br>
                    Theme by <a href="https://haojen.github.io/">Haojen Ma</a>
                </p>

            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="/js/blog.js"></script>

<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("http://yoursite.com/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>

<!-- Google Analytics -->



<!-- Baidu Tongji -->


<!-- swiftype -->
<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','null','2.0.0');
</script>

<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<!--wechat title img-->
<img class="wechat-title-img" src="http://7xrw7v.com1.z0.glb.clouddn.com/QQ%E6%88%AA%E5%9B%BE20160402220553.png">
</body>

</html>
